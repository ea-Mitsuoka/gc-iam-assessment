import os
import gspread
import pandas as pd
import json
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request

# --- è¨­å®šå€¤ ---
TFVARS_PATH = 'terraform/1_iam_assessor_deployment/terraform.tfvars'
SHEET_NAME = 'IAM Assessment Tool Specification'
SCOPES = [
    'https://www.googleapis.com/auth/spreadsheets',
    'https://www.googleapis.com/auth/drive'
]
CLIENT_SECRET_FILE = 'tools/client_secrets.json'
TOKEN_FILE = 'tools/token.json'

# --- èªè¨¼ ---
def authenticate_with_user_account():
    creds = None
    if os.path.exists(TOKEN_FILE):
        creds = Credentials.from_authorized_user_file(TOKEN_FILE, SCOPES)
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(CLIENT_SECRET_FILE, SCOPES)
            creds = flow.run_local_server(port=0)
        with open(TOKEN_FILE, 'w') as token:
            token.write(creds.to_json())
    return gspread.authorize(creds)

# --- ã‚·ãƒ¼ãƒˆèª­ã¿è¾¼ã¿ ---
def read_sheet_as_df(spreadsheet, sheet_name):
    print(f"Reading sheet: '{sheet_name}'...")
    try:
        worksheet = spreadsheet.worksheet(sheet_name)
        # ç©ºã®è¡Œã‚’é™¤å¤–ã—ã¦èª­ã¿è¾¼ã‚€ã‚ˆã†ã«æ”¹å–„ (ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã¯1è¡Œç›®ã¨ä»®å®š)
        records = worksheet.get_all_records(head=1, empty2zero=False, value_render_option='UNFORMATTED_VALUE')
        # å…¨ã¦ã®åˆ—ãŒç©ºã¾ãŸã¯Noneã§ã‚ã‚‹è¡Œã‚’é™¤å¤–
        records = [r for r in records if any(str(v).strip() for v in r.values())]
        df = pd.DataFrame(records)
        # FunctionNameåˆ—ãŒç©ºã®è¡Œã‚‚é™¤å¤– (å¿…é ˆåˆ—ã¨ã™ã‚‹) - Functionsã‚·ãƒ¼ãƒˆã®ã¿é©ç”¨
        if sheet_name == 'Functions' and 'FunctionName' in df.columns:
            df = df.dropna(subset=['FunctionName'])
            df = df[df['FunctionName'] != '']
        # RuleIDåˆ—ãŒç©ºã®è¡Œã‚‚é™¤å¤– (å¿…é ˆåˆ—ã¨ã™ã‚‹) - SoDRulesã‚·ãƒ¼ãƒˆã®ã¿é©ç”¨
        elif sheet_name == 'SoDRules' and 'RuleID' in df.columns:
            df = df.dropna(subset=['RuleID'])
            df = df[df['RuleID'] != '']
        # TableNameåˆ—ãŒç©ºã®è¡Œã‚‚é™¤å¤– (å¿…é ˆåˆ—ã¨ã™ã‚‹) - Tablesã‚·ãƒ¼ãƒˆã®ã¿é©ç”¨
        elif sheet_name == 'Tables' and 'TableName' in df.columns:
            df = df.dropna(subset=['TableName'])
            df = df[df['TableName'] != '']
        return df
    except gspread.WorksheetNotFound:
        print(f"Warning: Worksheet '{sheet_name}' not found.")
        return pd.DataFrame()
    except Exception as e:
        print(f"Error reading sheet '{sheet_name}': {e}")
        return pd.DataFrame()


# --- HCLç”Ÿæˆãƒ˜ãƒ«ãƒ‘ãƒ¼ ---
def generate_hcl_string(df, map_name, key_col, value_col):
    hcl_parts = [f"{map_name} = {{"]
    for _, row in df.iterrows():
        key = row.get(key_col)
        value = row.get(value_col)
        # ã‚­ãƒ¼ã¨å€¤ãŒä¸¡æ–¹å­˜åœ¨ã—ã€ç©ºã§ãªã„å ´åˆã®ã¿è¿½åŠ 
        if pd.notna(key) and key != '' and pd.notna(value) and value != '':
            hcl_parts.append(f'  "{key}" = "{value}"')
    hcl_parts.append("}")
    return "\n".join(hcl_parts)

# sod_rules_json ã‚’å¼•æ•°ã¨ã—ã¦å—ã‘å–ã‚‹ã‚ˆã†ã«å¤‰æ›´æ¸ˆ
def generate_functions_hcl(df, sod_rules_json=None):
    """assessment_functionsã®HCLã‚’ç”Ÿæˆã™ã‚‹"""
    hcl_parts = ["assessment_functions = {"]
    for _, row in df.iterrows():
        name = row.get('FunctionName')
        # FunctionNameãŒãªã„ã€ã¾ãŸã¯ç©ºã®è¡Œã¯ã‚¹ã‚­ãƒƒãƒ—
        if not name or pd.isna(name): continue

        hcl_parts.append(f'  "{name}" = {{')
        hcl_parts.append(f'    category = "{row.get("Category", "")}"')
        if pd.notna(row.get('Path')) and row.get('Path'): hcl_parts.append(f'    path = "{row.get("Path")}"')
        if pd.notna(row.get('Entry')) and row.get('Entry'): hcl_parts.append(f'    entry = "{row.get("Entry")}"')

        # IAMRolesåˆ—ã‚’å‡¦ç†
        roles_str = row.get('IAMRoles', '')
        roles = roles_str.strip().split('\n') if pd.notna(roles_str) else []
        hcl_parts.append(f'    service_account_roles = {json.dumps([r.strip() for r in roles if r.strip()])}')

        # EnvironmentVariablesåˆ—ã‚’å‡¦ç†
        env_vars_json_from_sheet = row.get('EnvironmentVariables')
        env_vars_dict = {}
        if pd.notna(env_vars_json_from_sheet) and env_vars_json_from_sheet:
            try:
                env_vars_dict = json.loads(env_vars_json_from_sheet)
                if not isinstance(env_vars_dict, dict):
                    print(f"*** WARNING: EnvironmentVariables for '{name}' is not a valid JSON object. Resetting to empty. Value: {env_vars_json_from_sheet}")
                    env_vars_dict = {} # ä¸æ­£ãªå ´åˆã¯ç©ºã«ã™ã‚‹
            except json.JSONDecodeError:
                print(f"*** WARNING: Skipping EnvironmentVariables for '{name}'. Invalid JSON: {env_vars_json_from_sheet}")
                env_vars_dict = {} # ãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã‚‚ç©ºã«ã™ã‚‹

        # sod-analyzerã®å ´åˆã€ç”Ÿæˆã—ãŸSOD_RULES_JSONã‚’ãƒãƒ¼ã‚¸
        if name == 'sod-analyzer' and sod_rules_json:
            # Functionsã‚·ãƒ¼ãƒˆå´ã®å®šç¾©ã‚’å„ªå…ˆã›ãšã€å¸¸ã«ä¸Šæ›¸ãã™ã‚‹
            env_vars_dict['SOD_RULES_JSON'] = sod_rules_json

        # ãƒãƒ¼ã‚¸å¾Œã®ç’°å¢ƒå¤‰æ•°ã‚’å‡ºåŠ› (ç©ºã§ãªã„å ´åˆã®ã¿)
        if env_vars_dict:
            env_hcl_parts = ["    environment_variables = {"]
            for k, v in env_vars_dict.items():
                env_hcl_parts.append(f'      "{k}" = {json.dumps(v)}')
            env_hcl_parts.append("    }")
            hcl_parts.append("\n".join(env_hcl_parts))

        hcl_parts.append('  }')
    hcl_parts.append("}")
    return "\n".join(hcl_parts)

# Functionsã‚·ãƒ¼ãƒˆã®DataFrameã‚’å—ã‘å–ã‚‹ã‚ˆã†ã«å¤‰æ›´æ¸ˆ
def generate_schedulers_hcl(df):
    """scheduler_configsã®HCLã‚’ç”Ÿæˆã™ã‚‹ (Functionsã‚·ãƒ¼ãƒˆã‹ã‚‰)"""
    hcl_parts = ["scheduler_configs = {"]
    for _, row in df.iterrows():
        name = row.get('FunctionName') # FunctionNameã‚’ã‚­ãƒ¼ã¨ã—ã¦ä½¿ç”¨
        schedule = row.get('Schedule')

        # FunctionNameãŒã‚ã‚Šã€ã‹ã¤ScheduleãŒç©ºã§ãªã„è¡Œã®ã¿å‡¦ç†
        if pd.notna(name) and name != '' and pd.notna(schedule) and schedule != '':
            hcl_parts.append(f'  "{name}" = {{')
            hcl_parts.append(f'    description = "{row.get("SchedulerDescription", "")}"')
            hcl_parts.append(f'    schedule    = "{schedule}"')
            hcl_parts.append('  }')
    hcl_parts.append("}")
    return "\n".join(hcl_parts)


# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
if __name__ == "__main__":
    client = authenticate_with_user_account()
    try:
        spreadsheet = client.open(SHEET_NAME)
    except gspread.SpreadsheetNotFound:
        print(f"Error: Spreadsheet '{SHEET_NAME}' not found.")
        exit()

    all_hcl_parts = []

    # 1. Settingsã‚·ãƒ¼ãƒˆã‚’å‡¦ç†
    settings_df = read_sheet_as_df(spreadsheet, "Settings")
    settings = {} # settingså¤‰æ•°ã‚’åˆæœŸåŒ–
    if not settings_df.empty:
        settings = pd.Series(settings_df.Value.values, index=settings_df.Key).to_dict()

        # --- å¤–éƒ¨ä¾å­˜ã®è¨­å®š ---
        all_hcl_parts.append("# --------------------------------------------------")
        all_hcl_parts.append("# å¤–éƒ¨ä¾å­˜ã®è¨­å®š")
        all_hcl_parts.append("# --------------------------------------------------")
        if 'gsuite_customer_id' in settings:
            all_hcl_parts.append(f'gsuite_customer_id = "{settings.pop("gsuite_customer_id", "")}"')
        all_hcl_parts.append("\n")
        # --- å…±é€šã§è¨­å®šãŒå¿…è¦ãªå¤‰æ•° ---
        all_hcl_parts.append("# --------------------------------------------------")
        all_hcl_parts.append("# å…±é€šã§è¨­å®šãŒå¿…è¦ãªå¤‰æ•°")
        all_hcl_parts.append("# --------------------------------------------------")
        if 'project_id' in settings:
            all_hcl_parts.append(f'project_id = "{settings.pop("project_id", "")}"')
        if 'terraform_service_account_email' in settings:
            all_hcl_parts.append(f'terraform_service_account_email = "{settings.pop("terraform_service_account_email", "")}"')
        all_hcl_parts.append("\n")
        # --- å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã®è¨­å®š ---
        all_hcl_parts.append("# --------------------------------------------------")
        all_hcl_parts.append("# å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã®è¨­å®š")
        all_hcl_parts.append("# --------------------------------------------------")
        if 'assessment_scope' in settings:
            all_hcl_parts.append(f'assessment_scope = "{settings.pop("assessment_scope", "ORGANIZATION")}"')
        if 'org_id' in settings:
            all_hcl_parts.append(f'org_id           = "{settings.pop("org_id", "")}"')
        if 'target_project_ids' in settings:
            value = settings.pop('target_project_ids', '')
            items = [item.strip() for item in str(value).split(',') if item.strip()]
            all_hcl_parts.append(f'target_project_ids = {json.dumps(items)}')
        all_hcl_parts.append("\n")
        # --- ã‚¤ãƒ³ãƒ•ãƒ©è¨­å®š ---
        all_hcl_parts.append("# --------------------------------------------------")
        all_hcl_parts.append("# âš™ï¸ ã‚¤ãƒ³ãƒ•ãƒ©è¨­å®š (å¤–éƒ¨ã‹ã‚‰å¤‰æ›´å¯èƒ½ã«ãªã£ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)")
        all_hcl_parts.append("# --------------------------------------------------")
        if 'enabled_apis' in settings:
            value = settings.pop('enabled_apis', '')
            items = [item.strip() for item in str(value).split(',') if item.strip()]
            all_hcl_parts.append(f'enabled_apis = {json.dumps(items)}')
        if 'bq_dataset_location' in settings:
            all_hcl_parts.append(f'bq_dataset_location = "{settings.pop("bq_dataset_location", "US")}"')
        if 'bq_dataset_id' in settings:
            all_hcl_parts.append(f'bq_dataset_id = "{settings.pop("bq_dataset_id", "iam_assessment_results")}"')
        if 'enable_force_destroy' in settings:
             force_destroy_val = str(settings.pop("enable_force_destroy", "false")).lower()
             all_hcl_parts.append(f'enable_force_destroy = {force_destroy_val}')
        all_hcl_parts.append("\n")
        # scheduler_time_zone ã¯å¾Œã§å‡¦ç†

    # 2. Tablesã‚·ãƒ¼ãƒˆã‚’å‡¦ç† (ä¿®æ­£: ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯æ—¢ã«å¯¾å¿œæ¸ˆã¿)
    tables_df = read_sheet_as_df(spreadsheet, "Tables")
    if not tables_df.empty:
        all_hcl_parts.append("# --------------------------------------------------")
        all_hcl_parts.append("# ãƒ†ãƒ¼ãƒ–ãƒ«åã¨ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°")
        all_hcl_parts.append("# --------------------------------------------------")
        all_hcl_parts.append(generate_hcl_string(tables_df, "table_schemas", "TableName", "SchemaPath"))
        all_hcl_parts.append("\n")
    else:
        # Tablesã‚·ãƒ¼ãƒˆãŒç©ºã§ã‚‚ãƒ–ãƒ­ãƒƒã‚¯ã ã‘ã¯å‡ºåŠ›ã™ã‚‹ (Terraformå¤‰æ•°å®šç¾©ã¨ã®æ•´åˆæ€§ã®ãŸã‚)
        all_hcl_parts.append("# --------------------------------------------------")
        all_hcl_parts.append("# ãƒ†ãƒ¼ãƒ–ãƒ«åã¨ã‚¹ã‚­ãƒ¼ãƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒãƒ”ãƒ³ã‚°")
        all_hcl_parts.append("# --------------------------------------------------")
        all_hcl_parts.append("table_schemas = {}")
        all_hcl_parts.append("\n")


    # SoDRulesã‚·ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿ã€JSONæ–‡å­—åˆ—ã‚’ç”Ÿæˆ
    sod_rules_df = read_sheet_as_df(spreadsheet, "SoDRules")
    sod_rules_json_string = "[]" # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    if not sod_rules_df.empty:
        expected_cols = ['RuleID', 'Description', 'Role1', 'Role2', 'Role1Type', 'Role2Type']
        rename_map = {
            'RuleID': 'rule_id', 'Description': 'description',
            'Role1': 'role1', 'Role2': 'role2',
            'Role1Type': 'role1_type', 'Role2Type': 'role2_type'
        }
        cols_to_use = [col for col in expected_cols if col in sod_rules_df.columns]
        if 'Role1' in cols_to_use and 'Role2' in cols_to_use: # Role1/2ã¯å¿…é ˆ
            sod_rules_list = []
            temp_df = sod_rules_df[cols_to_use].rename(columns=rename_map)
            for record in temp_df.to_dict('records'):
                roles1_str = record.get('role1', '')
                record['role1'] = [r.strip() for r in str(roles1_str).strip().split('\n') if r.strip()]
                roles2_str = record.get('role2', '')
                record['role2'] = [r.strip() for r in str(roles2_str).strip().split('\n') if r.strip()]
                if record.get('rule_id') and record['role1'] and record['role2']: # IDã¨Role1/2ãƒªã‚¹ãƒˆãŒç©ºã§ãªã„
                    sod_rules_list.append(record)
                else:
                    rule_id_log = record.get('rule_id', 'UNKNOWN')
                    print(f"*** WARNING: Skipping SoD rule '{rule_id_log}' due to missing ID or empty roles.")

            if sod_rules_list:
                sod_rules_json_string = json.dumps(sod_rules_list)
                print(f"Generated SOD_RULES_JSON from SoDRules sheet.")
            else:
                print("SoDRules sheet found, but no valid rules parsed. SOD_RULES_JSON will be '[]'.")
        else:
             print("SoDRules sheet found, but lacks required 'Role1' or 'Role2' columns. SOD_RULES_JSON will be '[]'.")
    else:
        print("SoDRules sheet is empty or not found. SOD_RULES_JSON will be '[]'.")

    # 3. Functionsã‚·ãƒ¼ãƒˆã‚’å‡¦ç† (Functionå®šç¾© + Schedulerå®šç¾©)
    functions_df = read_sheet_as_df(spreadsheet, "Functions")
    if not functions_df.empty:
        all_hcl_parts.append("# --------------------------------------------------")
        all_hcl_parts.append("# ğŸš€ è©•ä¾¡Functionã®å®šç¾©")
        all_hcl_parts.append("# --------------------------------------------------")
        # ç”Ÿæˆã—ãŸsod_rules_json_stringã‚’æ¸¡ã™
        all_hcl_parts.append(generate_functions_hcl(functions_df, sod_rules_json_string))
        all_hcl_parts.append("\n")

        # --- Schedulerå®šç¾© (ä¿®æ­£: ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯æ—¢ã«å¯¾å¿œæ¸ˆã¿) ---
        all_hcl_parts.append("# --------------------------------------------------")
        all_hcl_parts.append("# â° Schedulerã‚¸ãƒ§ãƒ–ã®å®šç¾©")
        all_hcl_parts.append("# --------------------------------------------------")
        if 'scheduler_time_zone' in settings:
             all_hcl_parts.append(f'scheduler_time_zone = "{settings.pop("scheduler_time_zone", "Asia/Tokyo")}"')
        # generate_schedulers_hcl ã« functions_df ã‚’æ¸¡ã™
        all_hcl_parts.append(generate_schedulers_hcl(functions_df))
        all_hcl_parts.append("\n")
    else:
        # Functionsã‚·ãƒ¼ãƒˆãŒç©ºã®å ´åˆã‚‚ãƒ–ãƒ­ãƒƒã‚¯ã ã‘ã¯å‡ºåŠ›
        all_hcl_parts.append("# --------------------------------------------------")
        all_hcl_parts.append("# ğŸš€ è©•ä¾¡Functionã®å®šç¾©")
        all_hcl_parts.append("# --------------------------------------------------")
        all_hcl_parts.append("assessment_functions = {}")
        all_hcl_parts.append("\n")
        all_hcl_parts.append("# --------------------------------------------------")
        all_hcl_parts.append("# â° Schedulerã‚¸ãƒ§ãƒ–ã®å®šç¾©")
        all_hcl_parts.append("# --------------------------------------------------")
        if 'scheduler_time_zone' in settings:
             all_hcl_parts.append(f'scheduler_time_zone = "{settings.pop("scheduler_time_zone", "Asia/Tokyo")}"')
        all_hcl_parts.append("scheduler_configs = {}")
        all_hcl_parts.append("\n")


    # 4. Settingsã‚·ãƒ¼ãƒˆã®æ®‹ã‚Š (æœªå‡¦ç†ã®è¨­å®šãŒã‚ã‚Œã°å‡ºåŠ›)
    if settings: # settingsè¾æ›¸ãŒç©ºã§ãªã„å ´åˆ
        all_hcl_parts.append("# --------------------------------------------------")
        all_hcl_parts.append("# ãã®ä»–ã®æœªåˆ†é¡è¨­å®š (Settingsã‚·ãƒ¼ãƒˆã‚ˆã‚Š)")
        all_hcl_parts.append("# --------------------------------------------------")
        for key, value in settings.items():
             # å€¤ãŒç©ºã®å ´åˆã‚‚ãã®ã¾ã¾å‡ºåŠ› (Terraformå´ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ãŒä½¿ã‚ã‚Œã‚‹ã“ã¨ã‚’æœŸå¾…)
             all_hcl_parts.append(f'{key} = "{value}"')
        all_hcl_parts.append("\n")

    # 5. tfvarsãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
    print(f"Writing all configurations to {TFVARS_PATH}...")
    with open(TFVARS_PATH, 'w', encoding='utf-8') as f:
            f.write("# ------------------------------------------------------------------\n")
            f.write("# WARNING: ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚\n")
            f.write("# æ‰‹å‹•ã§ç·¨é›†ã›ãšã€Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’æ›´æ–°ã—ãŸä¸Šã§\n")
            f.write("# `python tools/generate_tfvars.py` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\n")
            f.write("# ------------------------------------------------------------------\n\n")
            # ãƒªã‚¹ãƒˆã®æœ€å¾Œã®è¦ç´ ãŒç©ºè¡Œã ã£ãŸå ´åˆã«å‚™ãˆã¦rstrip()ã‚’è¿½åŠ ã—ã€æœ«å°¾ã«æ”¹è¡Œã‚’è¿½åŠ 
            f.write("\n".join(all_hcl_parts).rstrip() + "\n")
    print("tfvars file generation complete.")
